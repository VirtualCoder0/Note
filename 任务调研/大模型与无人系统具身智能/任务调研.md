### 01. LLM指令控制无人系统 问题调研

#### a. 任务定义

> **严格来说大语言模型不是直接控制机器人，而是[LLM for Robotics]([ChatGPT for Robotics](https://www.microsoft.com/en-us/research/articles/chatgpt-for-robotics))，以某种中间层的形式连接到底层的policy，最终还是底层的policy控制机器人。**

- ChatGPT for Robotics: Design Principles and Model Abilities   ([ChatGPT for Robotics](https://www.microsoft.com/en-us/research/articles/chatgpt-for-robotics))

  - 任务输入：详细的场景和任务的自然语言描述

    ![image-20250219195946038](https://raw.githubusercontent.com/VirtualCoder0/tuchuang/main/desktop/image-20250219195946038.png?token=ARXSUH7XZRURUA6UUV7ARQDHWXD7C)

    ![image-20250219200011049](https://raw.githubusercontent.com/VirtualCoder0/tuchuang/main/desktop/image-20250219200011049.png?token=ARXSUHYA6ZGJZJ7PL3QPJWDHWXEAU)

  - LLM 输出：基于预定义的规则输出机器人控制脚本

  - 该工作的意义在于解决了此前机器人控制研究中需要专业工程师人工将任务目标翻译为控制系统代码的问题，ChatGPT for Robotics 仅需要普通用户为大模型提供高纬度的机器人状态反馈就能基于定义好的规则让 LLM 输出机器人控制脚本，进一步完成预期任务。

    ![robotics today versus with chatgpt](https://www.microsoft.com/en-us/research/uploads/prod/2023/02/main.jpg)

  - 该工作并未实现无人系统全流程的自动化实现，过程中仍需要用户对机器人在场景中的情况进行描述。实质上是利用了 LLM 的零样本学习能力，使用对话交互，一步一步地将high-level任务分解为给定API

    - 局限性：**没有解决low-level control** 问题，底层的执行需要用到传统控制方法（比如模型预测方法[MPC](https://zhida.zhihu.com/search?content_id=233038879&content_type=Article&match_order=1&q=MPC&zd_token=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ6aGlkYV9zZXJ2ZXIiLCJleHAiOjE3NDAxMDUxMDgsInEiOiJNUEMiLCJ6aGlkYV9zb3VyY2UiOiJlbnRpdHkiLCJjb250ZW50X2lkIjoyMzMwMzg4NzksImNvbnRlbnRfdHlwZSI6IkFydGljbGUiLCJtYXRjaF9vcmRlciI6MSwiemRfdG9rZW4iOm51bGx9.JoGgfouLmpf4HYf5wXGc5WGkjXI-RcTp9z0gRf147Ec&zhida_source=entity)），它在某些场景不鲁棒，泛化性不强，而且同样需要大量手工设计。部分机器人的low-level control目前还存在瓶颈
      - ps: 部分机器人（比如自动驾驶的车、轮式机器人、机械臂）这些的low-level control好解决，但是足式机器人、人形机器人的low-level control不好解决




#### 问题思考

- 我们需要实现的任务场景中，任务的输入是什么形式？当前许多研究需要人工描述任务场景中的情况作为 LLM 的行为反馈
  - 使用的模型是语言模型还是多模态模型？
  - 视觉模型的优点：可以实现开放式词汇的视觉识别
- 是否具有无人系统的仿真系统作为 LLM 输出指令的测试反馈，如何进行有效的测试反馈？

- LLM 无论是使用思维链推理还是使用类似于 DeepSeek R1 的推理模型都需要很长的推理时间，这样的延迟在无人系统中是否可以接受？
